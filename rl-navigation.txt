$basePath = ''./results/{^^.name}/{^^.startTime}/''

$dT = 0.1
$tRange = m.range(min = 0; max = 30)

$emptyArena = ds.arena.prepared(
    name = empty;
    initialRobotXRange = m.range(min = 0.78; max = 0.8);
    initialRobotYRange = m.range(min = 0.45; max = 0.5);
    targetXRange = m.range(min = 0.2; max = 0.22);
    targetYRange = m.range(min = 0.3; max = 0.6)
  )
$a_barrierArena = ds.arena.prepared(
    name = a_barrier;
    initialRobotXRange = m.range(min = 0.45; max = 0.5);
    initialRobotYRange = m.range(min = 0.78; max = 0.8)
  )
$snakeArena = ds.arena.prepared(
    name = snake;
    initialRobotXRange = m.range(min = 0.1; max = 0.12);
    initialRobotYRange = m.range(min = 0.1; max = 0.12);
    targetXRange = m.range(min = 0.9; max = 0.95);
    targetYRange = m.range(min = 0.9; max = 0.95)
  )

$learningEnvs = (arena = [
  $emptyArena;
  $emptyArena;
  $emptyArena;
  $emptyArena;
  $emptyArena;
  $a_barrierArena;
  $a_barrierArena;
  $a_barrierArena;
  $a_barrierArena;
  $a_barrierArena;
  $snakeArena;
  $snakeArena;
  $snakeArena;
  $snakeArena;
  $snakeArena
])
* [ds.e.navigation(randomGenerator = m.sharedRG())]

$testEnvs = (arena = [
  $emptyArena;
  $a_barrierArena;
  $snakeArena
])
* [ds.e.navigation(randomGenerator = m.sharedRG())]

$exampleRLagent = ds.misc.simExample(simulation = ds.srlat.fromNumericalEnvironment(
  environment = ds.e.navigation(arena = ds.arena.prepared(name = empty));
  reward = ds.e.nav.reward.reaching()
))

ea.experiment(
  runs = (randomGenerator = (seed = [1:1:30]) * [m.defaultRG()])
  * (solver = (stop = ea.sc.nOfQualityEvaluations(n = 25000))
  * (representation = [ea.representation.doubleString()])
  * (mapper = [
    ea.mapper.ndsToNrla(name = "linear"; of = ea.mapper.dsToNpnds(npnds = ds.num.linear(zeroQ = false)));
    ea.mapper.ndsToNrla(name = "mlp"; of = ea.mapper.dsToNpnds(npnds = ds.num.mlp(innerLayers = [8])));
    ea.mapper.ndsToNrla(name = "hebbian+network+random"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = network; weightInitializationType = random)));
    ea.mapper.ndsToNrla(name = "hebbian+network+zeros"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = network; weightInitializationType = zeros)));
    ea.mapper.ndsToNrla(name = "hebbian+network+params"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = network; weightInitializationType = params)));
    ea.mapper.ndsToNrla(name = "hebbian+layer+random"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = layer; weightInitializationType = random)));
    ea.mapper.ndsToNrla(name = "hebbian+layer+zeros"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = layer; weightInitializationType = zeros)));
    ea.mapper.ndsToNrla(name = "hebbian+layer+params"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = layer; weightInitializationType = params)));
    ea.mapper.ndsToNrla(name = "hebbian+neuron+random"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = neuron; weightInitializationType = random)));
    ea.mapper.ndsToNrla(name = "hebbian+neuron+zeros"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = neuron; weightInitializationType = zeros)));
    ea.mapper.ndsToNrla(name = "hebbian+neuron+params"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = neuron; weightInitializationType = params)));
    ea.mapper.ndsToNrla(name = "hebbian+synapse+random"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = synapse; weightInitializationType = random)));
    ea.mapper.ndsToNrla(name = "hebbian+synapse+zeros"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = synapse; weightInitializationType = zeros)));
    ea.mapper.ndsToNrla(name = "hebbian+synapse+params"; of = ea.mapper.dsToNpnds(npnds = ds.num.hebbianMlp(innerLayers = [8]; parametrizationType = synapse; weightInitializationType = params)))
  ])
  * [ea.s.ga(name = ''ga+{mapper.name}'')
  ])
  * (problem = [
    ea.p.functionsToScbmo(
      cases = (of = (simulation = (environment = $learningEnvs)
      * [ds.srlat.fromNumericalEnvironment(reward = ds.e.nav.reward.reaching())])
      * [ds.f.simulate(dT = $dT; tRange = $tRange)])
      * [ds.f.cumulatedReward()];
      example = $exampleRLagent;
      toMaxObjectives = [f.as(of = f.avg(); name = avg)]
    )
  ])
  * [ea.run()];
  listeners = [
    ea.l.console(
      eFunctions = [
        ea.f.size(of = ea.f.genotype(of = ea.f.best()); format = "%4d");
        f.mapValue(key = avg; of = ea.f.quality(of = ea.f.best()); format = "%6.1f")
      ];
      onlyLast = false
    );
    ea.l.savePlotForExp(
      path = $basePath + "best-fitness.png";
      plot = ea.plot.multi.quality(q = f.mapValue(key = avg));
      type = png
    );
    ea.l.savePlotForExp(
      path = $basePath + "boxplot-best-fitness.png";
      plot = ea.plot.multi.qualityBoxplot(q = f.mapValue(key = avg));
      type = png
    );
    ea.l.saveForRun(
      path = $basePath + "{solver.name}/best-frozen-learning-trajs-{randomGenerator.seed:%02d}.png";
      of = ea.acc.lastBest();
      processor = viz.f.toMultiImage(
        drawer = ds.d.navigation();
        of = f.all(
          of = ds.f.stateless(of = ds.f.nonLearning(of = ea.f.solution()));
          fs = (simulation = (environment = $testEnvs)
          * [ds.sat.fromEnvironment()])
          * [ds.f.simulate(dT = $dT; tRange = $tRange)]
        );
        type = png
      )
    )
  ]
)